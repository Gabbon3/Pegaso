# 35 Gestione del processo del testing

Standard IEEE 829:
- Test Plan -> piano di battaglia
- Test Case Specification -> istruzioni operative
- Test Incident Report -> segnalazione di problemi
- Test Summary Report -> resoconto finale

## Quanto costa e quanto vale il testing

- Regola del 25% -> dice che il 25% delle risorse totali andrebbero usate per il test (quindi su 100.000€ 25.000€ andrebbero al test) meno % = software scadente
- Paradosso -> spesso si testa alla fine (quando tempo e soldi stanno finendo)
- Cultura della trasparenza -> il test è un ottimo indicatore oggettivo. ad esempio affermare "siamo ad un buon punto" != da "abbiamo superato l'85% dei test".

## Test Plan

suddiviso in 5 punti fondamentali

### 1 Obiettivi e criteri di accettazione

Criteri di accettazione = regole misurabili

### 2 Cosa testiamo e cosa NO

- In Scope -> cosa testerai
- Out of Scope -> cosa non testerai
- se non lo scrivi il cliente darà per scontato che hai fatto tutto e poi si potra lamentare

### 3 Strategia

- Userai approcci WhiteBox o Blackbox?
- test automatici o manuali?

### 4 Risorse e Ruoli

- definire chi è il _Tester_, chi il _QA Manager_, chi lo _Sviluppatore_ per correggere bug....
- Elencare anche gli _strumenti necessari_

### 5 Criteri di sospensione

Quando fermarci?

- se il software crasha di continuo non serve testare piu.
- bisogna quindi __definire una regola__

## Concetto chiave

Il Test Plan è un documento dinamico che si evolve in base ai requisiti che possono cambiare nel tempo come nella metodologia Agile.

In breve è un documento per tracciare tutte le scelte relative al test.

## Test Case Specification

documento con istruzioni passo passo per i tester

### 1 Regola della ripetitività

In breve il test case deve essere scritto bene per essere comprensibile a molti ma anche a te stesso del futuro.

### 2 Anatomia di un Test Case

Caratteristiche documento:
- id univoco
- descrizione
- precodnizioni -> cosa deve essere vero prima di iniziare? (es user deve essere loggato)
- input
- output atteso (l'__oracolo__ di cui si parlava qualche documento fa)
- Ambienti -> browser, OS...

### 3 indipendenza e modularita

Ogni test dovrebbe essere il piu indipendente possibile.

Questo per evitare problemi di dipendenze e fallimenti a cascata o falsi positivi.

### 4 Automazione

questo doc è la base per scrivere test automatici, poiche se sono stati scritti bene i passaggi manuali sarò semplice tradurli in codice robot

### 5 non solo Happy Path

bisogna scrivere anche test negativi, non testare solo se il sistema funziona ma fare test anche di stress come inserimento di dati errati, strani...

## Test Incident Report (TIR)

oh merda, ce un bug... bisogna compilare il TIR

### 1 fedina penale incidente

bisogna far si che chi lo legge sia in grado di riprodurlo
- id univoco
- ambiente
- output atteso vs effettivo
- prove

### 2 priorita vs gravita

- __gravita__ -> è un dato _tecnico_: quanto è rotto il sistema?
    - Alta: crasha e perde dati
    - Bassa: errore di battitura
- __priorita__ -> dato di _business_: quanto in fretta va risolto?
    - Alta: subito, questo bug è imbarazzante
    - Bassa: il sistema crasha ma solo se l utente preme tutti e 10 i tasti insieme.

le due caratteristiche non vanno a braccetto, un problema puo essere prioritario ma di bassa gravita (quindi esempio un errore di grammatica nella home page)

### 3 Ciclo di vita del bug

1. aperto -> tester segnala
2. in analisi -> sviluppatore analizza
3. corretto -> sviluppatore afferma di averlo risolto
4. verificato -> il tester verifica affermazione di sviluppatore
5. chiuso

## Test Summary Report (TSR)

per permettere il rilascio effettivo, va compilato il documento TSR per dichiarare un riassunto di tutto cio che è avvenuto prima quindi il piano i test case, i bug...

### 1 Tabellone

tabella piena di informazioni da pm a modi statistiche

### 2 analisi cause

non basta affermare che ci sono 8 errori, bisogna chiarire il perche

### 3 raccomandazione finale

cioe il verdetto, la parte piu corposa, il tester deve affermare esplicitamente una valutazione:
- __Ready for Release__ -> software stabile, bug risolti.
- __Not Ready__ -> ci sono troppi bug, software instabile, potremmo perdere clienti...

## Regression Test

Regressione = riesecuzione di test che avevi gia superato.

Serve a confermare che nuove modifiche non abbiamo rotto il codice precedente.

### Problema Retest-All

per il regression potresti dire: "ritestiamo tutto" ma se hai 10.000 test diventa complicato, ci vuole troppo tempo anche per piccole modifiche.

### 3 strategie intelligenti

- selection -> esegui test che toccano il codice modificato
- prioritization -> esegui prima i test critici. sicuramente pagamento > colore sfondo
- minimization -> elimina i test doppioni per alleggerire.

## Automazione test di regressione

1. usare robot per automatizzare operazioni ripetitive
2. CI/CD (Continous Integration / Continous Delivery): cuore dello sviluppo moderno:
    - Come funziona: appena il dev salva codice (commit) un sistema automatico come Jenkins o Gitlab lancia in automatico tutti i test di regression
    - risultato: se il commit rompe qualcosa lo sai subito e senza sforzo
3. attenzione alla manutenzione! l'automazione non è gratis, se cambi software devi riscrivere test di automazione.

## Buone Pratiche

- Tracciabilità direzionale -> ogni test dovrebbe essere legato ad un requisito, in questo modo puoi classificare facilmente l errore associato, la gravita e la priorita
- Collaborazione -> dev e tester devono comunicare ed essere alleati.